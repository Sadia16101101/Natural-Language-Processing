{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ZxIsSSa7r8xg",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZxIsSSa7r8xg",
    "outputId": "d04d394d-6ef4-4714-a045-7d180651e475"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "print(tensorflow.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d140813",
   "metadata": {
    "id": "d8372697"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import  SimpleRNN, Embedding,BatchNormalization, LSTM\n",
    "from tensorflow.keras.layers import Dense, Activation, Input, Dropout\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff44690",
   "metadata": {},
   "source": [
    "# Data Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b9f19f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"seq_train.csv\",  header=None,skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9ef8952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               0                                                  1\n",
      "0          55964  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...\n",
      "1          55965  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...\n",
      "2          55966  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...\n",
      "3          55967  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...\n",
      "4          55968  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...\n",
      "...          ...                                                ...\n",
      "7842831  9548408  3052 91 91 330 3146 3381 624 504 3194 2325 314...\n",
      "7842832  9548409  91 91 330 3146 3381 624 504 3194 2325 3146 200...\n",
      "7842833  9548410  91 330 3146 3381 624 504 3194 2325 3146 2009 3...\n",
      "7842834  9548411  330 3146 3381 624 504 3194 2325 3146 2009 3052...\n",
      "7842835  9548412  3146 3381 624 504 3194 2325 3146 2009 3052 272...\n",
      "\n",
      "[7842836 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a7cf3210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...\n",
      "1          0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...\n",
      "2          0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...\n",
      "3          0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...\n",
      "4          0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...\n",
      "                                 ...                        \n",
      "7842831    3052 91 91 330 3146 3381 624 504 3194 2325 314...\n",
      "7842832    91 91 330 3146 3381 624 504 3194 2325 3146 200...\n",
      "7842833    91 330 3146 3381 624 504 3194 2325 3146 2009 3...\n",
      "7842834    330 3146 3381 624 504 3194 2325 3146 2009 3052...\n",
      "7842835    3146 3381 624 504 3194 2325 3146 2009 3052 272...\n",
      "Name: 1, Length: 7842836, dtype: object\n",
      "(7842836,)\n"
     ]
    }
   ],
   "source": [
    "print(df[1])\n",
    "print(df[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8f9ae673",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_check=pd.read_csv('seq_train.csv', header=None,nrows=5000,skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c38f3186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0                                                  1\n",
      "0      55964  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...\n",
      "1      55965  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...\n",
      "2      55966  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...\n",
      "3      55967  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...\n",
      "4      55968  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ...\n",
      "...      ...                                                ...\n",
      "4995  451554  313 504 624 386 1248 2729 1902 846 624 3381 33...\n",
      "4996  451555  504 624 386 1248 2729 1902 846 624 3381 330 31...\n",
      "4997  451556  624 386 1248 2729 1902 846 624 3381 330 313 12...\n",
      "4998  451557  386 1248 2729 1902 846 624 3381 330 313 1248 6...\n",
      "4999  451558  1248 2729 1902 846 624 3381 330 313 1248 624 5...\n",
      "\n",
      "[5000 rows x 2 columns]\n",
      "(5000, 2)\n"
     ]
    }
   ],
   "source": [
    "print(df_check)\n",
    "print(df_check.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "21d330be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_check=df_check[1].str.split(' ',expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e9ffc282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0     1     2     3     4     5     6     7     8     9    ...   247  \\\n",
      "0        0     0     0     0     0     0     0     0     0     0  ...     0   \n",
      "1        0     0     0     0     0     0     0     0     0     0  ...     0   \n",
      "2        0     0     0     0     0     0     0     0     0     0  ...     0   \n",
      "3        0     0     0     0     0     0     0     0     0     0  ...     0   \n",
      "4        0     0     0     0     0     0     0     0     0     0  ...   816   \n",
      "...    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
      "4995   313   504   624   386  1248  2729  1902   846   624  3381  ...  1413   \n",
      "4996   504   624   386  1248  2729  1902   846   624  3381   330  ...  2325   \n",
      "4997   624   386  1248  2729  1902   846   624  3381   330   313  ...  1248   \n",
      "4998   386  1248  2729  1902   846   624  3381   330   313  1248  ...   624   \n",
      "4999  1248  2729  1902   846   624  3381   330   313  1248   624  ...    91   \n",
      "\n",
      "       248   249   250   251   252   253   254   255   256  \n",
      "0        0   816  1248   386  3146  2729  3052   624   782  \n",
      "1        0   816  1248   386  3146  2729  3052   624   782  \n",
      "2      816  1248   386  3146  2729  3052   624   782   782  \n",
      "3      816  1248   386  3146  2729  3052   624   782   782  \n",
      "4     1248   386  3146  2729  3052   624   782   782   782  \n",
      "...    ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
      "4995  2325  1248   624    91   386  1413  2111  2035   624  \n",
      "4996  1248   624    91   386  1413  2111  2035   624  2325  \n",
      "4997   624    91   386  1413  2111  2035   624  2325  3146  \n",
      "4998    91   386  1413  2111  2035   624  2325  3146  2729  \n",
      "4999   386  1413  2111  2035   624  2325  3146  2729   624  \n",
      "\n",
      "[5000 rows x 257 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "80467f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_y= df_check.iloc[: , 256:]\n",
    "check_x= df_check.iloc[: , :256]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9fa886d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       256\n",
      "0      782\n",
      "1      782\n",
      "2      782\n",
      "3      782\n",
      "4      782\n",
      "...    ...\n",
      "4995   624\n",
      "4996  2325\n",
      "4997  3146\n",
      "4998  2729\n",
      "4999   624\n",
      "\n",
      "[5000 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(check_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "34bcefc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0     1     2     3     4     5     6     7     8     9    ...   246  \\\n",
      "0        0     0     0     0     0     0     0     0     0     0  ...     0   \n",
      "1        0     0     0     0     0     0     0     0     0     0  ...     0   \n",
      "2        0     0     0     0     0     0     0     0     0     0  ...     0   \n",
      "3        0     0     0     0     0     0     0     0     0     0  ...     0   \n",
      "4        0     0     0     0     0     0     0     0     0     0  ...     0   \n",
      "...    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
      "4995   313   504   624   386  1248  2729  1902   846   624  3381  ...    91   \n",
      "4996   504   624   386  1248  2729  1902   846   624  3381   330  ...  1413   \n",
      "4997   624   386  1248  2729  1902   846   624  3381   330   313  ...  2325   \n",
      "4998   386  1248  2729  1902   846   624  3381   330   313  1248  ...  1248   \n",
      "4999  1248  2729  1902   846   624  3381   330   313  1248   624  ...   624   \n",
      "\n",
      "       247   248   249   250   251   252   253   254   255  \n",
      "0        0     0   816  1248   386  3146  2729  3052   624  \n",
      "1        0     0   816  1248   386  3146  2729  3052   624  \n",
      "2        0   816  1248   386  3146  2729  3052   624   782  \n",
      "3        0   816  1248   386  3146  2729  3052   624   782  \n",
      "4      816  1248   386  3146  2729  3052   624   782   782  \n",
      "...    ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
      "4995  1413  2325  1248   624    91   386  1413  2111  2035  \n",
      "4996  2325  1248   624    91   386  1413  2111  2035   624  \n",
      "4997  1248   624    91   386  1413  2111  2035   624  2325  \n",
      "4998   624    91   386  1413  2111  2035   624  2325  3146  \n",
      "4999    91   386  1413  2111  2035   624  2325  3146  2729  \n",
      "\n",
      "[5000 rows x 256 columns]\n"
     ]
    }
   ],
   "source": [
    "print(check_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ea5ffc",
   "metadata": {},
   "source": [
    "# Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f70d8982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 256)]             0         \n",
      "                                                                 \n",
      " embedding_1 (Embedding)     (None, 256, 100)          353700    \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 256, 100)          0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 100)               80400     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 100)              400       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3537)              357237    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 791,737\n",
      "Trainable params: 791,537\n",
      "Non-trainable params: 200\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "seqnc_lngth = 256\n",
    "vocab_size = 3537 \n",
    "embddng_dim = 100\n",
    "\n",
    "inpt_vec = Input(shape=(seqnc_lngth,))\n",
    "l1 = Embedding(vocab_size, embddng_dim, input_length=seqnc_lngth)(inpt_vec)\n",
    "l2 = Dropout(0.3)(l1)\n",
    "l3 = LSTM(100, activation='tanh',recurrent_activation='sigmoid')(l2)\n",
    "l4 = BatchNormalization()(l3)\n",
    "l5 = Dropout(0.3)(l4)\n",
    "l6 = Dense(vocab_size, activation='softmax')(l5)\n",
    "lstm = Model(inpt_vec, l6)\n",
    "lstm.compile(loss='sparse_categorical_crossentropy', optimizer=tensorflow.keras.optimizers.Adam(),metrics=['accuracy'])\n",
    "lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "635cd329",
   "metadata": {
    "id": "635cd329"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('seq_train.csv', header=None,chunksize = 100000,skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a57c49b9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a57c49b9",
    "outputId": "ddaa2aab-01d4-4e86-eca8-c44e10cac089"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1600/1600 [==============================] - 351s 218ms/step - loss: 3.2277 - accuracy: 0.2395 - val_loss: 2.6386 - val_accuracy: 0.2990\n",
      "Epoch 2/3\n",
      "1600/1600 [==============================] - 340s 213ms/step - loss: 2.5668 - accuracy: 0.3182 - val_loss: 2.4390 - val_accuracy: 0.3490\n",
      "Epoch 3/3\n",
      "1600/1600 [==============================] - 337s 211ms/step - loss: 2.3832 - accuracy: 0.3593 - val_loss: 2.2862 - val_accuracy: 0.3896\n",
      "Epoch 1/3\n",
      "1600/1600 [==============================] - 356s 222ms/step - loss: 2.3725 - accuracy: 0.3774 - val_loss: 2.2008 - val_accuracy: 0.4102\n",
      "Epoch 2/3\n",
      "1600/1600 [==============================] - 360s 225ms/step - loss: 2.1601 - accuracy: 0.4153 - val_loss: 2.0834 - val_accuracy: 0.4451\n",
      "Epoch 3/3\n",
      "1600/1600 [==============================] - 363s 227ms/step - loss: 2.0292 - accuracy: 0.4458 - val_loss: 2.0073 - val_accuracy: 0.4642\n",
      "Epoch 1/3\n",
      "1600/1600 [==============================] - 420s 262ms/step - loss: 2.2992 - accuracy: 0.4092 - val_loss: 2.0746 - val_accuracy: 0.4523\n",
      "Epoch 2/3\n",
      "1600/1600 [==============================] - 419s 262ms/step - loss: 2.0770 - accuracy: 0.4453 - val_loss: 1.9790 - val_accuracy: 0.4762\n",
      "Epoch 3/3\n",
      "1600/1600 [==============================] - 430s 269ms/step - loss: 1.9534 - accuracy: 0.4719 - val_loss: 1.9216 - val_accuracy: 0.4917\n",
      "Epoch 1/3\n",
      "1600/1600 [==============================] - 439s 275ms/step - loss: 2.2000 - accuracy: 0.4458 - val_loss: 1.9816 - val_accuracy: 0.4881\n",
      "Epoch 2/3\n",
      "1600/1600 [==============================] - 422s 263ms/step - loss: 1.9924 - accuracy: 0.4782 - val_loss: 1.8960 - val_accuracy: 0.5021\n",
      "Epoch 3/3\n",
      "1600/1600 [==============================] - 433s 271ms/step - loss: 1.8893 - accuracy: 0.4971 - val_loss: 1.8420 - val_accuracy: 0.5170\n",
      "Epoch 1/3\n",
      "1600/1600 [==============================] - 440s 275ms/step - loss: 2.1171 - accuracy: 0.4480 - val_loss: 1.8978 - val_accuracy: 0.4985\n",
      "Epoch 2/3\n",
      "1600/1600 [==============================] - 436s 273ms/step - loss: 1.9104 - accuracy: 0.4846 - val_loss: 1.8153 - val_accuracy: 0.5184\n",
      "Epoch 3/3\n",
      "1600/1600 [==============================] - 434s 271ms/step - loss: 1.8063 - accuracy: 0.5066 - val_loss: 1.7577 - val_accuracy: 0.5406\n",
      "Epoch 1/3\n",
      "1600/1600 [==============================] - 435s 272ms/step - loss: 2.0332 - accuracy: 0.4805 - val_loss: 1.7994 - val_accuracy: 0.5322\n",
      "Epoch 2/3\n",
      "1600/1600 [==============================] - 428s 268ms/step - loss: 1.8116 - accuracy: 0.5213 - val_loss: 1.6950 - val_accuracy: 0.5561\n",
      "Epoch 3/3\n",
      "1600/1600 [==============================] - 430s 269ms/step - loss: 1.6924 - accuracy: 0.5441 - val_loss: 1.6339 - val_accuracy: 0.5727\n",
      "Epoch 1/3\n",
      "1600/1600 [==============================] - 428s 267ms/step - loss: 2.1087 - accuracy: 0.4758 - val_loss: 1.8809 - val_accuracy: 0.5192\n",
      "Epoch 2/3\n",
      "1600/1600 [==============================] - 434s 271ms/step - loss: 1.9208 - accuracy: 0.5021 - val_loss: 1.8229 - val_accuracy: 0.5288\n",
      "Epoch 3/3\n",
      "1600/1600 [==============================] - 445s 278ms/step - loss: 1.8312 - accuracy: 0.5185 - val_loss: 1.7902 - val_accuracy: 0.5353\n",
      "Epoch 1/3\n",
      "1600/1600 [==============================] - 430s 269ms/step - loss: 2.0193 - accuracy: 0.4957 - val_loss: 1.8020 - val_accuracy: 0.5380\n",
      "Epoch 2/3\n",
      "1600/1600 [==============================] - 426s 266ms/step - loss: 1.8540 - accuracy: 0.5179 - val_loss: 1.7540 - val_accuracy: 0.5470\n",
      "Epoch 3/3\n",
      "1600/1600 [==============================] - 421s 263ms/step - loss: 1.7729 - accuracy: 0.5305 - val_loss: 1.7266 - val_accuracy: 0.5544\n",
      "Epoch 1/3\n",
      "1600/1600 [==============================] - 421s 263ms/step - loss: 2.0102 - accuracy: 0.4896 - val_loss: 1.8389 - val_accuracy: 0.5240\n",
      "Epoch 2/3\n",
      "1600/1600 [==============================] - 422s 264ms/step - loss: 1.8820 - accuracy: 0.5059 - val_loss: 1.8100 - val_accuracy: 0.5279\n",
      "Epoch 3/3\n",
      "1600/1600 [==============================] - 417s 261ms/step - loss: 1.8096 - accuracy: 0.5172 - val_loss: 1.7801 - val_accuracy: 0.5373\n",
      "Epoch 1/3\n",
      "1600/1600 [==============================] - 411s 257ms/step - loss: 1.9825 - accuracy: 0.5028 - val_loss: 1.7641 - val_accuracy: 0.5437\n",
      "Epoch 2/3\n",
      "1600/1600 [==============================] - 410s 256ms/step - loss: 1.8145 - accuracy: 0.5310 - val_loss: 1.7090 - val_accuracy: 0.5538\n",
      "Epoch 3/3\n",
      "1600/1600 [==============================] - 411s 257ms/step - loss: 1.7226 - accuracy: 0.5434 - val_loss: 1.6760 - val_accuracy: 0.5628\n",
      "Epoch 1/3\n",
      "1600/1600 [==============================] - 425s 266ms/step - loss: 2.0332 - accuracy: 0.4862 - val_loss: 1.8282 - val_accuracy: 0.5236\n",
      "Epoch 2/3\n",
      "1600/1600 [==============================] - 422s 264ms/step - loss: 1.8664 - accuracy: 0.5097 - val_loss: 1.7758 - val_accuracy: 0.5337\n",
      "Epoch 3/3\n",
      "1600/1600 [==============================] - 417s 261ms/step - loss: 1.7870 - accuracy: 0.5224 - val_loss: 1.7493 - val_accuracy: 0.5383\n",
      "Epoch 1/3\n",
      "1600/1600 [==============================] - 422s 264ms/step - loss: 1.9502 - accuracy: 0.5072 - val_loss: 1.7816 - val_accuracy: 0.5434\n",
      "Epoch 2/3\n",
      "1600/1600 [==============================] - 420s 263ms/step - loss: 1.8032 - accuracy: 0.5297 - val_loss: 1.7445 - val_accuracy: 0.5489\n",
      "Epoch 3/3\n",
      "1600/1600 [==============================] - 421s 263ms/step - loss: 1.7327 - accuracy: 0.5426 - val_loss: 1.7160 - val_accuracy: 0.5519\n",
      "Epoch 1/3\n",
      "1600/1600 [==============================] - 425s 266ms/step - loss: 1.9840 - accuracy: 0.5002 - val_loss: 1.7799 - val_accuracy: 0.5373\n",
      "Epoch 2/3\n",
      "1600/1600 [==============================] - 424s 265ms/step - loss: 1.8255 - accuracy: 0.5208 - val_loss: 1.7409 - val_accuracy: 0.5444\n",
      "Epoch 3/3\n",
      "1600/1600 [==============================] - 419s 262ms/step - loss: 1.7478 - accuracy: 0.5341 - val_loss: 1.7052 - val_accuracy: 0.5523\n",
      "Epoch 1/3\n",
      "1600/1600 [==============================] - 408s 255ms/step - loss: 1.9144 - accuracy: 0.5180 - val_loss: 1.7369 - val_accuracy: 0.5539\n",
      "Epoch 2/3\n",
      "1600/1600 [==============================] - 428s 267ms/step - loss: 1.7698 - accuracy: 0.5382 - val_loss: 1.6987 - val_accuracy: 0.5575\n",
      "Epoch 3/3\n",
      "1600/1600 [==============================] - 427s 267ms/step - loss: 1.6935 - accuracy: 0.5497 - val_loss: 1.6709 - val_accuracy: 0.5641\n",
      "Epoch 1/3\n",
      "1600/1600 [==============================] - 423s 265ms/step - loss: 1.8836 - accuracy: 0.5170 - val_loss: 1.7121 - val_accuracy: 0.5601\n",
      "Epoch 2/3\n",
      "1600/1600 [==============================] - 421s 263ms/step - loss: 1.7491 - accuracy: 0.5384 - val_loss: 1.6719 - val_accuracy: 0.5688\n",
      "Epoch 3/3\n",
      "1600/1600 [==============================] - 424s 265ms/step - loss: 1.6737 - accuracy: 0.5516 - val_loss: 1.6413 - val_accuracy: 0.5762\n",
      "Epoch 1/3\n",
      "1600/1600 [==============================] - 428s 267ms/step - loss: 1.8901 - accuracy: 0.5214 - val_loss: 1.7424 - val_accuracy: 0.5477\n",
      "Epoch 2/3\n",
      "1600/1600 [==============================] - 428s 268ms/step - loss: 1.7594 - accuracy: 0.5402 - val_loss: 1.6953 - val_accuracy: 0.5583\n",
      "Epoch 3/3\n",
      "1600/1600 [==============================] - 429s 268ms/step - loss: 1.6897 - accuracy: 0.5501 - val_loss: 1.6771 - val_accuracy: 0.5634\n",
      "Epoch 1/3\n",
      "1600/1600 [==============================] - 425s 266ms/step - loss: 1.9833 - accuracy: 0.5094 - val_loss: 1.7840 - val_accuracy: 0.5480\n",
      "Epoch 2/3\n",
      "1600/1600 [==============================] - 417s 261ms/step - loss: 1.8204 - accuracy: 0.5306 - val_loss: 1.7379 - val_accuracy: 0.5537\n",
      "Epoch 3/3\n",
      "1600/1600 [==============================] - 420s 262ms/step - loss: 1.7410 - accuracy: 0.5428 - val_loss: 1.7069 - val_accuracy: 0.5612\n",
      "Epoch 1/3\n",
      "1600/1600 [==============================] - 429s 268ms/step - loss: 1.8801 - accuracy: 0.5197 - val_loss: 1.6940 - val_accuracy: 0.5587\n",
      "Epoch 2/3\n",
      "1600/1600 [==============================] - 424s 265ms/step - loss: 1.7428 - accuracy: 0.5411 - val_loss: 1.6506 - val_accuracy: 0.5682\n",
      "Epoch 3/3\n",
      "1600/1600 [==============================] - 423s 264ms/step - loss: 1.6680 - accuracy: 0.5539 - val_loss: 1.6137 - val_accuracy: 0.5770\n",
      "Epoch 1/3\n",
      "1600/1600 [==============================] - 422s 264ms/step - loss: 1.8947 - accuracy: 0.5176 - val_loss: 1.7128 - val_accuracy: 0.5511\n",
      "Epoch 2/3\n",
      "1600/1600 [==============================] - 423s 265ms/step - loss: 1.7582 - accuracy: 0.5392 - val_loss: 1.6688 - val_accuracy: 0.5626\n",
      "Epoch 3/3\n",
      "1600/1600 [==============================] - 424s 265ms/step - loss: 1.6915 - accuracy: 0.5484 - val_loss: 1.6447 - val_accuracy: 0.5669\n",
      "Epoch 1/3\n",
      "1600/1600 [==============================] - 432s 270ms/step - loss: 1.9382 - accuracy: 0.5175 - val_loss: 1.7355 - val_accuracy: 0.5595\n",
      "Epoch 2/3\n",
      "1600/1600 [==============================] - 430s 269ms/step - loss: 1.7909 - accuracy: 0.5403 - val_loss: 1.7000 - val_accuracy: 0.5638\n",
      "Epoch 3/3\n",
      "1600/1600 [==============================] - 431s 269ms/step - loss: 1.7208 - accuracy: 0.5483 - val_loss: 1.6790 - val_accuracy: 0.5691\n",
      "Epoch 1/3\n",
      "1600/1600 [==============================] - 434s 271ms/step - loss: 1.9880 - accuracy: 0.5044 - val_loss: 1.8189 - val_accuracy: 0.5391\n",
      "Epoch 2/3\n",
      "1600/1600 [==============================] - 435s 272ms/step - loss: 1.8539 - accuracy: 0.5225 - val_loss: 1.7855 - val_accuracy: 0.5418\n",
      "Epoch 3/3\n",
      "1600/1600 [==============================] - 433s 271ms/step - loss: 1.7785 - accuracy: 0.5359 - val_loss: 1.7589 - val_accuracy: 0.5495\n",
      "Epoch 1/3\n",
      "1600/1600 [==============================] - 432s 270ms/step - loss: 1.8768 - accuracy: 0.5260 - val_loss: 1.6830 - val_accuracy: 0.5670\n",
      "Epoch 2/3\n",
      "1600/1600 [==============================] - 433s 271ms/step - loss: 1.7464 - accuracy: 0.5465 - val_loss: 1.6443 - val_accuracy: 0.5712\n",
      "Epoch 3/3\n",
      "1600/1600 [==============================] - 432s 270ms/step - loss: 1.6762 - accuracy: 0.5566 - val_loss: 1.6152 - val_accuracy: 0.5802\n",
      "Epoch 1/3\n",
      "1600/1600 [==============================] - 440s 275ms/step - loss: 2.0393 - accuracy: 0.5063 - val_loss: 1.8127 - val_accuracy: 0.5432\n",
      "Epoch 2/3\n",
      "1600/1600 [==============================] - 441s 276ms/step - loss: 1.8809 - accuracy: 0.5232 - val_loss: 1.7727 - val_accuracy: 0.5468\n",
      "Epoch 3/3\n",
      "1600/1600 [==============================] - 440s 275ms/step - loss: 1.8009 - accuracy: 0.5327 - val_loss: 1.7519 - val_accuracy: 0.5483\n",
      "Epoch 1/3\n",
      "1600/1600 [==============================] - 429s 268ms/step - loss: 1.9297 - accuracy: 0.5121 - val_loss: 1.7708 - val_accuracy: 0.5390\n",
      "Epoch 2/3\n",
      "1600/1600 [==============================] - 433s 271ms/step - loss: 1.8054 - accuracy: 0.5298 - val_loss: 1.7305 - val_accuracy: 0.5487\n",
      "Epoch 3/3\n",
      "1600/1600 [==============================] - 435s 272ms/step - loss: 1.7445 - accuracy: 0.5371 - val_loss: 1.7150 - val_accuracy: 0.5523\n",
      "Epoch 1/3\n",
      "1600/1600 [==============================] - 436s 273ms/step - loss: 1.9503 - accuracy: 0.5141 - val_loss: 1.7689 - val_accuracy: 0.5441\n",
      "Epoch 2/3\n",
      "1600/1600 [==============================] - 431s 269ms/step - loss: 1.8151 - accuracy: 0.5301 - val_loss: 1.7395 - val_accuracy: 0.5466\n",
      "Epoch 3/3\n",
      "1600/1600 [==============================] - 430s 269ms/step - loss: 1.7501 - accuracy: 0.5399 - val_loss: 1.7236 - val_accuracy: 0.5491\n",
      "Epoch 1/3\n",
      "1600/1600 [==============================] - 433s 271ms/step - loss: 2.2281 - accuracy: 0.4880 - val_loss: 1.9986 - val_accuracy: 0.5258\n",
      "Epoch 2/3\n",
      "1600/1600 [==============================] - 428s 268ms/step - loss: 2.0269 - accuracy: 0.5074 - val_loss: 1.9358 - val_accuracy: 0.5336\n",
      "Epoch 3/3\n",
      "1600/1600 [==============================] - 429s 268ms/step - loss: 1.9265 - accuracy: 0.5169 - val_loss: 1.9163 - val_accuracy: 0.5349\n",
      "Epoch 1/3\n",
      "1600/1600 [==============================] - 442s 276ms/step - loss: 1.9276 - accuracy: 0.5142 - val_loss: 1.7679 - val_accuracy: 0.5480\n",
      "Epoch 2/3\n",
      "1600/1600 [==============================] - 446s 279ms/step - loss: 1.8099 - accuracy: 0.5306 - val_loss: 1.7407 - val_accuracy: 0.5481\n",
      "Epoch 3/3\n",
      "1600/1600 [==============================] - 443s 277ms/step - loss: 1.7507 - accuracy: 0.5397 - val_loss: 1.7220 - val_accuracy: 0.5556\n",
      "Epoch 1/3\n",
      "1600/1600 [==============================] - 453s 283ms/step - loss: 1.8959 - accuracy: 0.5131 - val_loss: 1.7111 - val_accuracy: 0.5513\n",
      "Epoch 2/3\n",
      "1600/1600 [==============================] - 435s 272ms/step - loss: 1.7626 - accuracy: 0.5340 - val_loss: 1.6699 - val_accuracy: 0.5608\n",
      "Epoch 3/3\n",
      "1600/1600 [==============================] - 440s 275ms/step - loss: 1.6929 - accuracy: 0.5456 - val_loss: 1.6474 - val_accuracy: 0.5664\n",
      "Epoch 1/3\n",
      "1600/1600 [==============================] - 439s 274ms/step - loss: 1.9004 - accuracy: 0.5155 - val_loss: 1.7245 - val_accuracy: 0.5469\n",
      "Epoch 2/3\n",
      "1600/1600 [==============================] - 436s 273ms/step - loss: 1.7660 - accuracy: 0.5353 - val_loss: 1.6897 - val_accuracy: 0.5538\n",
      "Epoch 3/3\n",
      "1600/1600 [==============================] - 439s 274ms/step - loss: 1.7004 - accuracy: 0.5470 - val_loss: 1.6711 - val_accuracy: 0.5555\n",
      "Epoch 1/3\n",
      "1600/1600 [==============================] - 431s 270ms/step - loss: 1.8819 - accuracy: 0.5201 - val_loss: 1.7468 - val_accuracy: 0.5458\n",
      "Epoch 2/3\n",
      "1600/1600 [==============================] - 431s 269ms/step - loss: 1.7607 - accuracy: 0.5344 - val_loss: 1.7156 - val_accuracy: 0.5566\n",
      "Epoch 3/3\n",
      "1600/1600 [==============================] - 431s 269ms/step - loss: 1.7029 - accuracy: 0.5459 - val_loss: 1.6975 - val_accuracy: 0.5576\n",
      "Epoch 1/3\n",
      "1600/1600 [==============================] - 427s 267ms/step - loss: 1.8473 - accuracy: 0.5310 - val_loss: 1.7063 - val_accuracy: 0.5595\n",
      "Epoch 2/3\n",
      "1600/1600 [==============================] - 427s 267ms/step - loss: 1.7465 - accuracy: 0.5476 - val_loss: 1.6832 - val_accuracy: 0.5645\n",
      "Epoch 3/3\n",
      "1600/1600 [==============================] - 427s 267ms/step - loss: 1.6981 - accuracy: 0.5533 - val_loss: 1.6672 - val_accuracy: 0.5709\n",
      "Epoch 1/3\n",
      "1600/1600 [==============================] - 438s 274ms/step - loss: 1.9488 - accuracy: 0.5245 - val_loss: 1.7672 - val_accuracy: 0.5566\n",
      "Epoch 2/3\n",
      "1600/1600 [==============================] - 431s 270ms/step - loss: 1.8082 - accuracy: 0.5405 - val_loss: 1.7307 - val_accuracy: 0.5590\n",
      "Epoch 3/3\n",
      "1600/1600 [==============================] - 433s 271ms/step - loss: 1.7378 - accuracy: 0.5476 - val_loss: 1.7128 - val_accuracy: 0.5632\n",
      "Epoch 1/3\n",
      "1600/1600 [==============================] - 437s 273ms/step - loss: 1.8494 - accuracy: 0.5290 - val_loss: 1.6529 - val_accuracy: 0.5655\n",
      "Epoch 2/3\n",
      "1600/1600 [==============================] - 436s 272ms/step - loss: 1.7317 - accuracy: 0.5425 - val_loss: 1.6230 - val_accuracy: 0.5671\n",
      "Epoch 3/3\n",
      "1600/1600 [==============================] - 436s 272ms/step - loss: 1.6719 - accuracy: 0.5547 - val_loss: 1.6036 - val_accuracy: 0.5741\n",
      "Epoch 1/3\n",
      "1600/1600 [==============================] - 443s 277ms/step - loss: 1.9244 - accuracy: 0.5125 - val_loss: 1.7829 - val_accuracy: 0.5432\n",
      "Epoch 2/3\n",
      "1600/1600 [==============================] - 440s 275ms/step - loss: 1.8090 - accuracy: 0.5294 - val_loss: 1.7520 - val_accuracy: 0.5470\n",
      "Epoch 3/3\n",
      "1600/1600 [==============================] - 455s 284ms/step - loss: 1.7504 - accuracy: 0.5366 - val_loss: 1.7358 - val_accuracy: 0.5528\n",
      "Epoch 1/3\n",
      "1600/1600 [==============================] - 451s 282ms/step - loss: 1.9384 - accuracy: 0.5132 - val_loss: 1.7469 - val_accuracy: 0.5504\n",
      "Epoch 2/3\n",
      "1600/1600 [==============================] - 467s 292ms/step - loss: 1.8150 - accuracy: 0.5304 - val_loss: 1.7166 - val_accuracy: 0.5555\n",
      "Epoch 3/3\n",
      "1600/1600 [==============================] - 458s 286ms/step - loss: 1.7504 - accuracy: 0.5370 - val_loss: 1.7031 - val_accuracy: 0.5570\n",
      "Epoch 1/3\n",
      "1600/1600 [==============================] - 438s 274ms/step - loss: 1.8839 - accuracy: 0.5240 - val_loss: 1.7084 - val_accuracy: 0.5548\n",
      "Epoch 2/3\n",
      "1600/1600 [==============================] - 434s 271ms/step - loss: 1.7644 - accuracy: 0.5385 - val_loss: 1.6809 - val_accuracy: 0.5593\n",
      "Epoch 3/3\n",
      "1600/1600 [==============================] - 429s 268ms/step - loss: 1.7092 - accuracy: 0.5466 - val_loss: 1.6699 - val_accuracy: 0.5627\n",
      "Epoch 1/3\n",
      "1600/1600 [==============================] - 446s 279ms/step - loss: 1.8665 - accuracy: 0.5301 - val_loss: 1.6948 - val_accuracy: 0.5669\n",
      "Epoch 2/3\n",
      "1600/1600 [==============================] - 445s 278ms/step - loss: 1.7522 - accuracy: 0.5463 - val_loss: 1.6719 - val_accuracy: 0.5686\n",
      "Epoch 3/3\n",
      "1600/1600 [==============================] - 445s 278ms/step - loss: 1.6990 - accuracy: 0.5544 - val_loss: 1.6569 - val_accuracy: 0.5710\n",
      "Epoch 1/3\n",
      "1600/1600 [==============================] - 446s 279ms/step - loss: 1.8866 - accuracy: 0.5198 - val_loss: 1.7157 - val_accuracy: 0.5533\n",
      "Epoch 2/3\n",
      "1600/1600 [==============================] - 436s 272ms/step - loss: 1.7801 - accuracy: 0.5361 - val_loss: 1.6952 - val_accuracy: 0.5586\n",
      "Epoch 3/3\n",
      "1600/1600 [==============================] - 440s 275ms/step - loss: 1.7186 - accuracy: 0.5448 - val_loss: 1.6902 - val_accuracy: 0.5609\n",
      "Epoch 1/3\n",
      "1600/1600 [==============================] - 450s 281ms/step - loss: 1.9520 - accuracy: 0.5196 - val_loss: 1.8099 - val_accuracy: 0.5495\n",
      "Epoch 2/3\n",
      "1600/1600 [==============================] - 447s 279ms/step - loss: 1.8278 - accuracy: 0.5349 - val_loss: 1.7793 - val_accuracy: 0.5551\n",
      "Epoch 3/3\n",
      "1600/1600 [==============================] - 445s 278ms/step - loss: 1.7654 - accuracy: 0.5424 - val_loss: 1.7625 - val_accuracy: 0.5586\n",
      "Epoch 1/3\n",
      "1600/1600 [==============================] - 451s 282ms/step - loss: 1.9746 - accuracy: 0.5173 - val_loss: 1.7903 - val_accuracy: 0.5486\n",
      "Epoch 2/3\n",
      "1600/1600 [==============================] - 452s 282ms/step - loss: 1.8323 - accuracy: 0.5330 - val_loss: 1.7546 - val_accuracy: 0.5515\n",
      "Epoch 3/3\n",
      "1600/1600 [==============================] - 458s 286ms/step - loss: 1.7660 - accuracy: 0.5423 - val_loss: 1.7380 - val_accuracy: 0.5555\n",
      "Epoch 1/3\n",
      "1600/1600 [==============================] - 454s 284ms/step - loss: 1.8770 - accuracy: 0.5278 - val_loss: 1.7094 - val_accuracy: 0.5566\n",
      "Epoch 2/3\n",
      "1600/1600 [==============================] - 446s 279ms/step - loss: 1.7736 - accuracy: 0.5409 - val_loss: 1.6877 - val_accuracy: 0.5642\n",
      "Epoch 3/3\n",
      "1600/1600 [==============================] - 451s 282ms/step - loss: 1.7175 - accuracy: 0.5493 - val_loss: 1.6795 - val_accuracy: 0.5645\n",
      "Epoch 1/3\n",
      "1600/1600 [==============================] - 466s 291ms/step - loss: 1.8925 - accuracy: 0.5251 - val_loss: 1.7336 - val_accuracy: 0.5524\n",
      "Epoch 2/3\n",
      "1600/1600 [==============================] - 466s 291ms/step - loss: 1.7821 - accuracy: 0.5405 - val_loss: 1.7192 - val_accuracy: 0.5549\n",
      "Epoch 3/3\n",
      "1600/1600 [==============================] - 454s 284ms/step - loss: 1.7281 - accuracy: 0.5468 - val_loss: 1.7051 - val_accuracy: 0.5586\n",
      "Epoch 1/3\n",
      "1600/1600 [==============================] - 448s 280ms/step - loss: 1.8580 - accuracy: 0.5360 - val_loss: 1.6579 - val_accuracy: 0.5745\n",
      "Epoch 2/3\n",
      "1600/1600 [==============================] - 463s 289ms/step - loss: 1.7506 - accuracy: 0.5476 - val_loss: 1.6389 - val_accuracy: 0.5768\n",
      "Epoch 3/3\n",
      "1600/1600 [==============================] - 451s 282ms/step - loss: 1.7029 - accuracy: 0.5525 - val_loss: 1.6587 - val_accuracy: 0.5721\n",
      "Epoch 1/3\n",
      "1600/1600 [==============================] - 454s 284ms/step - loss: 1.8766 - accuracy: 0.5220 - val_loss: 1.7109 - val_accuracy: 0.5542\n",
      "Epoch 2/3\n",
      "1600/1600 [==============================] - 460s 287ms/step - loss: 1.7875 - accuracy: 0.5350 - val_loss: 1.6854 - val_accuracy: 0.5591\n",
      "Epoch 3/3\n",
      "1600/1600 [==============================] - 470s 294ms/step - loss: 1.7396 - accuracy: 0.5403 - val_loss: 1.6772 - val_accuracy: 0.5616\n",
      "Epoch 1/3\n",
      "1600/1600 [==============================] - 465s 291ms/step - loss: 1.8988 - accuracy: 0.5301 - val_loss: 1.7452 - val_accuracy: 0.5558\n",
      "Epoch 2/3\n",
      "1600/1600 [==============================] - 464s 290ms/step - loss: 1.7825 - accuracy: 0.5421 - val_loss: 1.7179 - val_accuracy: 0.5577\n",
      "Epoch 3/3\n",
      "1600/1600 [==============================] - 453s 283ms/step - loss: 1.7277 - accuracy: 0.5465 - val_loss: 1.7077 - val_accuracy: 0.5612\n",
      "Epoch 1/3\n",
      "1600/1600 [==============================] - 438s 274ms/step - loss: 1.8550 - accuracy: 0.5259 - val_loss: 1.6841 - val_accuracy: 0.5608\n",
      "Epoch 2/3\n",
      "1600/1600 [==============================] - 434s 271ms/step - loss: 1.7609 - accuracy: 0.5381 - val_loss: 1.6676 - val_accuracy: 0.5605\n",
      "Epoch 3/3\n",
      "1600/1600 [==============================] - 434s 271ms/step - loss: 1.7121 - accuracy: 0.5456 - val_loss: 1.6621 - val_accuracy: 0.5610\n",
      "Epoch 1/3\n",
      "1600/1600 [==============================] - 443s 277ms/step - loss: 1.8977 - accuracy: 0.5205 - val_loss: 1.7391 - val_accuracy: 0.5488\n",
      "Epoch 2/3\n",
      "1600/1600 [==============================] - 444s 277ms/step - loss: 1.7898 - accuracy: 0.5317 - val_loss: 1.7183 - val_accuracy: 0.5509\n",
      "Epoch 3/3\n",
      "1600/1600 [==============================] - 443s 277ms/step - loss: 1.7335 - accuracy: 0.5404 - val_loss: 1.7103 - val_accuracy: 0.5519\n",
      "Epoch 1/3\n",
      "1600/1600 [==============================] - 427s 267ms/step - loss: 1.9233 - accuracy: 0.5205 - val_loss: 1.7645 - val_accuracy: 0.5473\n",
      "Epoch 2/3\n",
      "1600/1600 [==============================] - 425s 265ms/step - loss: 1.7951 - accuracy: 0.5365 - val_loss: 1.7413 - val_accuracy: 0.5502\n",
      "Epoch 3/3\n",
      "1600/1600 [==============================] - 423s 264ms/step - loss: 1.7384 - accuracy: 0.5439 - val_loss: 1.7239 - val_accuracy: 0.5541\n",
      "Epoch 1/3\n",
      "1600/1600 [==============================] - 432s 270ms/step - loss: 1.8923 - accuracy: 0.5275 - val_loss: 1.7378 - val_accuracy: 0.5557\n",
      "Epoch 2/3\n",
      "1600/1600 [==============================] - 435s 272ms/step - loss: 1.7779 - accuracy: 0.5443 - val_loss: 1.7125 - val_accuracy: 0.5591\n",
      "Epoch 3/3\n",
      "1600/1600 [==============================] - 431s 269ms/step - loss: 1.7215 - accuracy: 0.5497 - val_loss: 1.7040 - val_accuracy: 0.5604\n",
      "Epoch 1/3\n",
      "1600/1600 [==============================] - 434s 271ms/step - loss: 1.8504 - accuracy: 0.5339 - val_loss: 1.6974 - val_accuracy: 0.5681\n",
      "Epoch 2/3\n",
      "1600/1600 [==============================] - 433s 271ms/step - loss: 1.7555 - accuracy: 0.5476 - val_loss: 1.6737 - val_accuracy: 0.5672\n",
      "Epoch 3/3\n",
      "1600/1600 [==============================] - 448s 280ms/step - loss: 1.7005 - accuracy: 0.5538 - val_loss: 1.6643 - val_accuracy: 0.5716\n",
      "Epoch 1/3\n",
      "1600/1600 [==============================] - 440s 275ms/step - loss: 1.8438 - accuracy: 0.5342 - val_loss: 1.7160 - val_accuracy: 0.5659\n",
      "Epoch 2/3\n",
      "1600/1600 [==============================] - 443s 277ms/step - loss: 1.7479 - accuracy: 0.5464 - val_loss: 1.7060 - val_accuracy: 0.5650\n",
      "Epoch 3/3\n",
      "1600/1600 [==============================] - 437s 273ms/step - loss: 1.7033 - accuracy: 0.5541 - val_loss: 1.6959 - val_accuracy: 0.5700\n",
      "Epoch 1/3\n",
      "1600/1600 [==============================] - 459s 287ms/step - loss: 1.8805 - accuracy: 0.5340 - val_loss: 1.7109 - val_accuracy: 0.5670\n",
      "Epoch 2/3\n",
      "1600/1600 [==============================] - 451s 282ms/step - loss: 1.7662 - accuracy: 0.5447 - val_loss: 1.6770 - val_accuracy: 0.5710\n",
      "Epoch 3/3\n",
      "1600/1600 [==============================] - 439s 274ms/step - loss: 1.7122 - accuracy: 0.5517 - val_loss: 1.6617 - val_accuracy: 0.5718\n",
      "Epoch 1/3\n",
      "1600/1600 [==============================] - 437s 273ms/step - loss: 1.8302 - accuracy: 0.5373 - val_loss: 1.6414 - val_accuracy: 0.5706\n",
      "Epoch 2/3\n",
      "1600/1600 [==============================] - 448s 280ms/step - loss: 1.7356 - accuracy: 0.5473 - val_loss: 1.6295 - val_accuracy: 0.5721\n",
      "Epoch 3/3\n",
      "1600/1600 [==============================] - 457s 286ms/step - loss: 1.6852 - accuracy: 0.5556 - val_loss: 1.6316 - val_accuracy: 0.5735\n",
      "Epoch 1/3\n",
      "1600/1600 [==============================] - 443s 277ms/step - loss: 1.8610 - accuracy: 0.5357 - val_loss: 1.6695 - val_accuracy: 0.5652\n",
      "Epoch 2/3\n",
      "1600/1600 [==============================] - 446s 279ms/step - loss: 1.7455 - accuracy: 0.5467 - val_loss: 1.6523 - val_accuracy: 0.5664\n",
      "Epoch 3/3\n",
      "1600/1600 [==============================] - 458s 286ms/step - loss: 1.6967 - accuracy: 0.5531 - val_loss: 1.6422 - val_accuracy: 0.5677\n",
      "Epoch 1/3\n",
      "1600/1600 [==============================] - 467s 292ms/step - loss: 1.8716 - accuracy: 0.5333 - val_loss: 1.7042 - val_accuracy: 0.5593\n",
      "Epoch 2/3\n",
      "1600/1600 [==============================] - 462s 288ms/step - loss: 1.7547 - accuracy: 0.5478 - val_loss: 1.6861 - val_accuracy: 0.5649\n",
      "Epoch 3/3\n",
      "1600/1600 [==============================] - 468s 293ms/step - loss: 1.7030 - accuracy: 0.5522 - val_loss: 1.6681 - val_accuracy: 0.5694\n",
      "Epoch 1/3\n",
      "1600/1600 [==============================] - 445s 278ms/step - loss: 1.8986 - accuracy: 0.5223 - val_loss: 1.7260 - val_accuracy: 0.5547\n",
      "Epoch 2/3\n",
      "1600/1600 [==============================] - 458s 286ms/step - loss: 1.7919 - accuracy: 0.5353 - val_loss: 1.7097 - val_accuracy: 0.5580\n",
      "Epoch 3/3\n",
      "1600/1600 [==============================] - 461s 288ms/step - loss: 1.7331 - accuracy: 0.5440 - val_loss: 1.7067 - val_accuracy: 0.5599\n",
      "Epoch 1/3\n",
      "1600/1600 [==============================] - 464s 290ms/step - loss: 1.9078 - accuracy: 0.5266 - val_loss: 1.7621 - val_accuracy: 0.5512\n",
      "Epoch 2/3\n",
      "1600/1600 [==============================] - 465s 291ms/step - loss: 1.7844 - accuracy: 0.5414 - val_loss: 1.7312 - val_accuracy: 0.5581\n",
      "Epoch 3/3\n",
      "1600/1600 [==============================] - 456s 285ms/step - loss: 1.7234 - accuracy: 0.5475 - val_loss: 1.7234 - val_accuracy: 0.5604\n",
      "Epoch 1/3\n",
      "1600/1600 [==============================] - 459s 287ms/step - loss: 1.9265 - accuracy: 0.5230 - val_loss: 1.7600 - val_accuracy: 0.5531\n",
      "Epoch 2/3\n",
      "1600/1600 [==============================] - 450s 281ms/step - loss: 1.8188 - accuracy: 0.5360 - val_loss: 1.7404 - val_accuracy: 0.5554\n",
      "Epoch 3/3\n",
      "1600/1600 [==============================] - 443s 277ms/step - loss: 1.7600 - accuracy: 0.5435 - val_loss: 1.7354 - val_accuracy: 0.5574\n",
      "Epoch 1/3\n",
      "1600/1600 [==============================] - 471s 294ms/step - loss: 1.8930 - accuracy: 0.5284 - val_loss: 1.7110 - val_accuracy: 0.5644\n",
      "Epoch 2/3\n",
      "1600/1600 [==============================] - 470s 294ms/step - loss: 1.7855 - accuracy: 0.5413 - val_loss: 1.6895 - val_accuracy: 0.5637\n",
      "Epoch 3/3\n",
      "1600/1600 [==============================] - 478s 299ms/step - loss: 1.7310 - accuracy: 0.5463 - val_loss: 1.6841 - val_accuracy: 0.5654\n",
      "Epoch 1/3\n",
      "1600/1600 [==============================] - 460s 288ms/step - loss: 1.8117 - accuracy: 0.5331 - val_loss: 1.6442 - val_accuracy: 0.5691\n",
      "Epoch 2/3\n",
      "1600/1600 [==============================] - 468s 293ms/step - loss: 1.7252 - accuracy: 0.5451 - val_loss: 1.6274 - val_accuracy: 0.5696\n",
      "Epoch 3/3\n",
      "1600/1600 [==============================] - 461s 288ms/step - loss: 1.6757 - accuracy: 0.5530 - val_loss: 1.6189 - val_accuracy: 0.5722\n",
      "Epoch 1/3\n",
      "1600/1600 [==============================] - 440s 275ms/step - loss: 1.8490 - accuracy: 0.5289 - val_loss: 1.7098 - val_accuracy: 0.5552\n",
      "Epoch 2/3\n",
      "1600/1600 [==============================] - 434s 271ms/step - loss: 1.7586 - accuracy: 0.5407 - val_loss: 1.6942 - val_accuracy: 0.5574\n",
      "Epoch 3/3\n",
      "1600/1600 [==============================] - 432s 270ms/step - loss: 1.7084 - accuracy: 0.5475 - val_loss: 1.6927 - val_accuracy: 0.5571\n",
      "Epoch 1/3\n",
      "1600/1600 [==============================] - 436s 272ms/step - loss: 1.8594 - accuracy: 0.5324 - val_loss: 1.6994 - val_accuracy: 0.5620\n",
      "Epoch 2/3\n",
      "1600/1600 [==============================] - 460s 287ms/step - loss: 1.7457 - accuracy: 0.5460 - val_loss: 1.6845 - val_accuracy: 0.5631\n",
      "Epoch 3/3\n",
      "1600/1600 [==============================] - 433s 271ms/step - loss: 1.6910 - accuracy: 0.5546 - val_loss: 1.6744 - val_accuracy: 0.5673\n",
      "Epoch 1/3\n",
      "1600/1600 [==============================] - 437s 273ms/step - loss: 1.7366 - accuracy: 0.5569 - val_loss: 1.6021 - val_accuracy: 0.5898\n",
      "Epoch 2/3\n",
      "1600/1600 [==============================] - 437s 273ms/step - loss: 1.6484 - accuracy: 0.5691 - val_loss: 1.5889 - val_accuracy: 0.5925\n",
      "Epoch 3/3\n",
      "1600/1600 [==============================] - 435s 272ms/step - loss: 1.6077 - accuracy: 0.5739 - val_loss: 1.5785 - val_accuracy: 0.5917\n",
      "Epoch 1/3\n",
      "1600/1600 [==============================] - 440s 275ms/step - loss: 1.8731 - accuracy: 0.5265 - val_loss: 1.7193 - val_accuracy: 0.5549\n",
      "Epoch 2/3\n",
      "1600/1600 [==============================] - 440s 275ms/step - loss: 1.7721 - accuracy: 0.5416 - val_loss: 1.7027 - val_accuracy: 0.5598\n",
      "Epoch 3/3\n",
      "1600/1600 [==============================] - 446s 278ms/step - loss: 1.7271 - accuracy: 0.5450 - val_loss: 1.6956 - val_accuracy: 0.5594\n",
      "Epoch 1/3\n",
      "1600/1600 [==============================] - 430s 269ms/step - loss: 1.8311 - accuracy: 0.5359 - val_loss: 1.6695 - val_accuracy: 0.5695\n",
      "Epoch 2/3\n",
      "1600/1600 [==============================] - 430s 269ms/step - loss: 1.7446 - accuracy: 0.5489 - val_loss: 1.6619 - val_accuracy: 0.5686\n",
      "Epoch 3/3\n",
      "1600/1600 [==============================] - 433s 270ms/step - loss: 1.6987 - accuracy: 0.5526 - val_loss: 1.6586 - val_accuracy: 0.5689\n",
      "Epoch 1/3\n",
      "1600/1600 [==============================] - 438s 274ms/step - loss: 1.9644 - accuracy: 0.5267 - val_loss: 1.8064 - val_accuracy: 0.5569\n",
      "Epoch 2/3\n",
      "1600/1600 [==============================] - 430s 269ms/step - loss: 1.8308 - accuracy: 0.5388 - val_loss: 1.7855 - val_accuracy: 0.5601\n",
      "Epoch 3/3\n",
      "1600/1600 [==============================] - 436s 273ms/step - loss: 1.7703 - accuracy: 0.5470 - val_loss: 1.7760 - val_accuracy: 0.5577\n",
      "Epoch 1/3\n",
      "1600/1600 [==============================] - 453s 283ms/step - loss: 1.8926 - accuracy: 0.5279 - val_loss: 1.7601 - val_accuracy: 0.5552\n",
      "Epoch 2/3\n",
      "1600/1600 [==============================] - 455s 285ms/step - loss: 1.7864 - accuracy: 0.5408 - val_loss: 1.7406 - val_accuracy: 0.5604\n",
      "Epoch 3/3\n",
      "1600/1600 [==============================] - 456s 285ms/step - loss: 1.7308 - accuracy: 0.5492 - val_loss: 1.7359 - val_accuracy: 0.5598\n",
      "Epoch 1/3\n",
      "1600/1600 [==============================] - 433s 271ms/step - loss: 1.8368 - accuracy: 0.5342 - val_loss: 1.6804 - val_accuracy: 0.5651\n",
      "Epoch 2/3\n",
      "1600/1600 [==============================] - 433s 271ms/step - loss: 1.7556 - accuracy: 0.5447 - val_loss: 1.6713 - val_accuracy: 0.5663\n",
      "Epoch 3/3\n",
      "1600/1600 [==============================] - 433s 271ms/step - loss: 1.7150 - accuracy: 0.5482 - val_loss: 1.6651 - val_accuracy: 0.5663\n",
      "Epoch 1/3\n",
      "1600/1600 [==============================] - 437s 273ms/step - loss: 1.9677 - accuracy: 0.5225 - val_loss: 1.8088 - val_accuracy: 0.5516\n",
      "Epoch 2/3\n",
      "1600/1600 [==============================] - 442s 276ms/step - loss: 1.8602 - accuracy: 0.5335 - val_loss: 1.7860 - val_accuracy: 0.5531\n",
      "Epoch 3/3\n",
      "1600/1600 [==============================] - 450s 281ms/step - loss: 1.8018 - accuracy: 0.5408 - val_loss: 1.7786 - val_accuracy: 0.5538\n",
      "Epoch 1/3\n",
      "1600/1600 [==============================] - 455s 284ms/step - loss: 1.8533 - accuracy: 0.5321 - val_loss: 1.7175 - val_accuracy: 0.5590\n",
      "Epoch 2/3\n",
      "1600/1600 [==============================] - 450s 282ms/step - loss: 1.7538 - accuracy: 0.5447 - val_loss: 1.7082 - val_accuracy: 0.5629\n",
      "Epoch 3/3\n",
      "1600/1600 [==============================] - 445s 278ms/step - loss: 1.7039 - accuracy: 0.5508 - val_loss: 1.7028 - val_accuracy: 0.5652\n",
      "Epoch 1/3\n",
      "1600/1600 [==============================] - 432s 270ms/step - loss: 1.8999 - accuracy: 0.5269 - val_loss: 1.7413 - val_accuracy: 0.5558\n",
      "Epoch 2/3\n",
      "1600/1600 [==============================] - 429s 268ms/step - loss: 1.7861 - accuracy: 0.5388 - val_loss: 1.7234 - val_accuracy: 0.5619\n",
      "Epoch 3/3\n",
      "1600/1600 [==============================] - 431s 269ms/step - loss: 1.7315 - accuracy: 0.5472 - val_loss: 1.7170 - val_accuracy: 0.5623\n",
      "Epoch 1/3\n",
      "1600/1600 [==============================] - 438s 274ms/step - loss: 1.8569 - accuracy: 0.5365 - val_loss: 1.7115 - val_accuracy: 0.5638\n",
      "Epoch 2/3\n",
      "1600/1600 [==============================] - 440s 275ms/step - loss: 1.7577 - accuracy: 0.5467 - val_loss: 1.6965 - val_accuracy: 0.5638\n",
      "Epoch 3/3\n",
      "1600/1600 [==============================] - 441s 276ms/step - loss: 1.7101 - accuracy: 0.5525 - val_loss: 1.6909 - val_accuracy: 0.5648\n",
      "Epoch 1/3\n",
      "1600/1600 [==============================] - 444s 277ms/step - loss: 1.8054 - accuracy: 0.5409 - val_loss: 1.6623 - val_accuracy: 0.5714\n",
      "Epoch 2/3\n",
      "1600/1600 [==============================] - 443s 277ms/step - loss: 1.7221 - accuracy: 0.5512 - val_loss: 1.6581 - val_accuracy: 0.5724\n",
      "Epoch 3/3\n",
      "1600/1600 [==============================] - 440s 275ms/step - loss: 1.6822 - accuracy: 0.5555 - val_loss: 1.6541 - val_accuracy: 0.5703\n",
      "Epoch 1/3\n",
      "1600/1600 [==============================] - 439s 275ms/step - loss: 1.8360 - accuracy: 0.5328 - val_loss: 1.7154 - val_accuracy: 0.5563\n",
      "Epoch 2/3\n",
      "1600/1600 [==============================] - 436s 272ms/step - loss: 1.7507 - accuracy: 0.5447 - val_loss: 1.7075 - val_accuracy: 0.5561\n",
      "Epoch 3/3\n",
      "1600/1600 [==============================] - 438s 273ms/step - loss: 1.7087 - accuracy: 0.5479 - val_loss: 1.7043 - val_accuracy: 0.5579\n",
      "Epoch 1/3\n",
      "1600/1600 [==============================] - 446s 279ms/step - loss: 1.8571 - accuracy: 0.5316 - val_loss: 1.6830 - val_accuracy: 0.5624\n",
      "Epoch 2/3\n",
      "1600/1600 [==============================] - 447s 280ms/step - loss: 1.7787 - accuracy: 0.5417 - val_loss: 1.6707 - val_accuracy: 0.5673\n",
      "Epoch 3/3\n",
      "1600/1600 [==============================] - 447s 279ms/step - loss: 1.7331 - accuracy: 0.5478 - val_loss: 1.6678 - val_accuracy: 0.5666\n",
      "Epoch 1/3\n",
      "1600/1600 [==============================] - 437s 273ms/step - loss: 1.9003 - accuracy: 0.5288 - val_loss: 1.7465 - val_accuracy: 0.5610\n",
      "Epoch 2/3\n",
      "1600/1600 [==============================] - 432s 270ms/step - loss: 1.7913 - accuracy: 0.5407 - val_loss: 1.7262 - val_accuracy: 0.5620\n",
      "Epoch 3/3\n",
      "1600/1600 [==============================] - 434s 271ms/step - loss: 1.7389 - accuracy: 0.5451 - val_loss: 1.7178 - val_accuracy: 0.5641\n",
      "Epoch 1/3\n",
      "1600/1600 [==============================] - 458s 286ms/step - loss: 1.8876 - accuracy: 0.5307 - val_loss: 1.7287 - val_accuracy: 0.5581\n",
      "Epoch 2/3\n",
      "1600/1600 [==============================] - 464s 290ms/step - loss: 1.7752 - accuracy: 0.5441 - val_loss: 1.7138 - val_accuracy: 0.5592\n",
      "Epoch 3/3\n",
      "1600/1600 [==============================] - 448s 280ms/step - loss: 1.7274 - accuracy: 0.5475 - val_loss: 1.7092 - val_accuracy: 0.5599\n",
      "Epoch 1/3\n",
      "1600/1600 [==============================] - 410s 256ms/step - loss: 1.8356 - accuracy: 0.5319 - val_loss: 1.7162 - val_accuracy: 0.5516\n",
      "Epoch 2/3\n",
      "1600/1600 [==============================] - 432s 270ms/step - loss: 1.7553 - accuracy: 0.5418 - val_loss: 1.7036 - val_accuracy: 0.5556\n",
      "Epoch 3/3\n",
      "1600/1600 [==============================] - 436s 273ms/step - loss: 1.7121 - accuracy: 0.5463 - val_loss: 1.7014 - val_accuracy: 0.5547\n",
      "Epoch 1/3\n",
      "686/686 [==============================] - 198s 287ms/step - loss: 1.8124 - accuracy: 0.5350 - val_loss: 1.7010 - val_accuracy: 0.5543\n",
      "Epoch 2/3\n",
      "686/686 [==============================] - 187s 273ms/step - loss: 1.7119 - accuracy: 0.5487 - val_loss: 1.6908 - val_accuracy: 0.5560\n",
      "Epoch 3/3\n",
      "686/686 [==============================] - 184s 269ms/step - loss: 1.6596 - accuracy: 0.5578 - val_loss: 1.6977 - val_accuracy: 0.5552\n"
     ]
    }
   ],
   "source": [
    "for df in data:\n",
    "    df=df[1].str.split(' ',expand=True)\n",
    "    y= df.iloc[: , 256:]\n",
    "    x= df.iloc[: , :256]\n",
    "    x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.3, random_state=4)\n",
    "\n",
    "    x_train = np.asarray(x_train,dtype='float32')\n",
    "    x_test = np.asarray(x_test,dtype='float32')\n",
    "    y_train = np.asarray(y_train,dtype='float32')\n",
    "    y_test = np.asarray(y_test,dtype='float32')\n",
    "    Y = [int(i) for i in y_train]\n",
    "    Y = np.asarray(Y,dtype='float32')\n",
    "\n",
    "\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3,min_delta=1e-4, mode='min', verbose=1)\n",
    "    stop_alg = EarlyStopping(monitor='val_loss', patience=7,restore_best_weights=True, verbose=1)\n",
    "\n",
    "\n",
    "    hist = lstm.fit(x_train, Y , batch_size=64, epochs=3, shuffle=True,validation_data = (x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b7c7eb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(10,6))\n",
    "plt.plot(hist.history['loss'], color='#785ef0')\n",
    "plt.plot(hist.history['val_loss'], color='#dc267f')\n",
    "plt.title('Model Loss Progress')\n",
    "plt.ylabel('Categorical Cross-Entropy Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Training Set', 'Test Set'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6PhyrmAs7za5",
   "metadata": {
    "id": "6PhyrmAs7za5"
   },
   "outputs": [],
   "source": [
    "lstm.save(\"version_2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bOWBMneLNMtb",
   "metadata": {
    "id": "bOWBMneLNMtb"
   },
   "outputs": [],
   "source": [
    "def prediction(x_test):\n",
    "    y_pred = model.predict(x_test)\n",
    "    pred = list(np.argmax(y_pred, axis=1))\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61b134b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"seq_test.csv\", header=None,chunksize = 100000,skiprows=1)\n",
    "count=0\n",
    "for df in test_data:\n",
    "    result=[]\n",
    "    df=df[1].str.split(' ',expand=True)\n",
    "    x = df.to_numpy()\n",
    "    x = x.astype('float32')\n",
    "    filename= \"test\"+str(count)+\".csv\"\n",
    "    result=prediction(x)\n",
    "    df_result = pd.DataFrame(result)\n",
    "    df_result.to_csv(filename)\n",
    "    count=count+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b075c81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3119c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = glob.glob(\"C:\\Users\\sadia_tisha1\\Desktop\\NLP Assignment\" + \"/*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661c9ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_from_each_file = (pd.read_csv(f, sep=',') for f in all_files)\n",
    "df_merged   = pd.concat(df_from_each_file, ignore_index=True)\n",
    "df_merged.to_csv( \"samplesubmission.csv\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "NLP chunk.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
